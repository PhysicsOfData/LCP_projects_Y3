{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Respiratory rate estimation\n",
    "\n",
    "### Description\n",
    "\n",
    "Seismocardiography([SCG](https://www.ncbi.nlm.nih.gov/pubmed/24111357) is a very promising technique to measure Heart Rate (HR) and Respiratory Rate (RR) with the detector positioned above sternum. It is generally based on accelerometer and gyroscope readings or a combination of them.\n",
    "Ballistocardiography([BCG](https://en.wikipedia.org/wiki/Ballistocardiography)) is an another technique to estimate heart and respiratory rate with combination of both accelerometer and gyroscope. It is an indirect evaluation of HR and RR since the contact between the device and the body of the subject is not required (e.g., accelerometer platform mounted under the slats of the bed).\n",
    "MuSe(Multi-Sensor miniaturized, low-power, wireless [IMU](https://en.wikipedia.org/wiki/Inertial_measurement_unit)) is an Inertial Measurement Unit (IMU) provide by (221e)[https://www.221e.com]. In the context of this project, It allows to record the inertial data necessary for the estimation of SCG and BCG.\n",
    "The goal of this assignment is to estimate the respiratory rate of an healthy subject, given linear acceleration and angular velocity measurements recorded by using the aforementioned MuSe platform. The study must be performed on two datasets: the first is the compulsory one (center_sternum.txt) while the second is left at the discretion of the group, among those made available for the assignment.\n",
    "N.B: Remember that normal beat is around 40-100 bpm.\n",
    "\n",
    "[Actigraphy](https://en.wikipedia.org/wiki/Actigraphy) is a non-invasive method of monitoring human rest/activity cycles. Data will be provided from sensors gathering data on humans during their day/night activities\n",
    "\n",
    "### Datasets\n",
    "\n",
    "The data is provided in .txt file. During this study two healthy subjects were involved with their informed consent. The first dataset was recorded on one subject, while all the other datasets were recorded on the second subject.\n",
    "\n",
    "This is the first mandatory file:\n",
    "* center_sternum.txt: MuSe placed on the center of the sternum. The subject was lying supine on his left and right side, respectively.\n",
    "\n",
    "Choose one of the following files in order to complete the task.\n",
    "1. 1_Stave_supine_static.txt: Sensor placed on a bed stave, under the mattress at the level of the chest. The subject was lying supine on his left and right side.\n",
    "2. 2_Mattress_supine.txt: Sensor placed on the mattress, near one corner but not under the pillow. The subject laid in the same position as above.\n",
    "3. 3_Subject_sitting_chair.txt: Sensor placed on the desk: the subject, sitting on a chair, leaned forearms and hands on the desk.\n",
    "4. 4_Chest_sweater.txt: Sensor placed on the subject chest directly on a sweater.\n",
    "5. 5_Under_chair.txt: Subject sitting on a chair, sensor placed under the seat of the chair.\n",
    "\n",
    "All .txt files give 16 columns index, in particular:\n",
    "* Log Freq stands for the acquisition in Hz (i.e., sampling interval is constant).\n",
    "* AccX, AccY, AccZ are the measured magnitude of linear acceleration along each axis.\n",
    "* GyroX, GyroY, GyroZ are the measured magnitude of angular velocity along each axis.\n",
    "* MagnX, MagnY, MagnZ are the measured magnitude of magnetic field along each axis.\n",
    "* qw, qi, qj, qk are the quaternion components, representing the spatial orientation of the Muse\n",
    "system.\n",
    "\n",
    "Each dataset includes, in addition to the data, one file containing the adopted configuration of the MuSe(README1.txt for the first measurement, and in README_5.txt for the other measurement).\n",
    " \n",
    "### Assignments\n",
    "\n",
    "Data preparation:\n",
    "\n",
    "1.1. Load the txt file and select only the columns you are interesting in, in order to do a complete data analysis (e.g. Log Freq, AccX, ... )\n",
    "\n",
    "1.2. Plot selected data in function of time and choose a properly time window over which to perform the analysis. Pay attention on time rappresentation and the measurament unit.\n",
    "\n",
    "1.3. In order to make an appropiate work, decide if take care about some particular axis or some combination of them as well as derived features for the next step of the task. Motivate your choice.\n",
    "\n",
    "Time and frequency analysis:\n",
    "\n",
    "2.1. Statistical analysis: provide a statistical description of the chosen dataset. Statistical\n",
    "descriptors includes for example mean, median, variance, standard deviation, 25th and 75th percentiles, and correlation coefficients. Investigate what could be the most interesting descriptors for this type of data, motivating the choices.\n",
    "\n",
    "2.2. Fourier Analysis: Perform a frequency analysis of the data. Look at the spectrum and explain what you see. Use this step in order to properly design the filters in the following step.\n",
    "\n",
    "Filter:\n",
    "\n",
    "Implement your own filter, trying to extrapolate respiratory rate signal. Hint:\n",
    "\n",
    "(a) Directly from Fourier Analysis, antitrasform data looking for the most interesting frequency band.\n",
    "\n",
    "(b) Choose the appropriate Lowpass/Bandpass/Highpass filter.\n",
    "\n",
    "(c) Wavelet trasform (a powerfull instrument that make a time and frequency analysis of signal). \n",
    "\n",
    "(d) Find another method by yourselves.\n",
    "\n",
    "Motivate your choice.\n",
    "\n",
    "Metrics:\n",
    "\n",
    "4.1. Respiratory Rate Per Minute(RPM): extrapolate RPM, make an histogram of the result. Does it follow a partiular distribution?\n",
    "\n",
    "4.2. Respiratory Rate Variability(RRV): extrapolate RRV, explain why this parameter is important, and plot the results.\n",
    "\n",
    "(OPTIONAL) Algorithm: Elaborate a simple algorithm to extrapolate respiratory rate even when filter failed (e.g. look at particular threshold...).\n",
    "\n",
    "Conclusion:\n",
    " Summarise the obtained results, in particular making a comparison between the two files analysed. Highlight limitation and critical issues encountered during the work, motivating the most relevant contribution given by your solution.\n",
    "\n",
    "N.B: Indicate the contribution, to achieving the result, of each member of the group.\n",
    "\n",
    " \n",
    "\n",
    "### Contacts\n",
    "\n",
    "* Marco Zanetti <marco.zanetti@unipd.it>\n",
    "* Marco Signorelli <signo@221e.com>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from scipy import ndimage\n",
    "import statistics\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import butter, lfilter\n",
    "from scipy.signal import freqz\n",
    "import heartpy as hp\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import find_peaks\n",
    "%matplotlib inline\n",
    "import pywt\n",
    "import scaleogram as scg \n",
    "import matplotlib.gridspec as GridSpec\n",
    "from mat4py import loadmat\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from scipy import fftpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mandatory dataset\n",
    "file_name=\"center_sternum.txt\"\n",
    "data=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "time_step1 = 1/200\n",
    "index = data.index\n",
    "number_of_rows1 = len(index)\n",
    "time_vec1 = np.arange(0, number_of_rows1 * time_step1, time_step1)\n",
    "data.insert(0, 'new_seconds', time_vec1)\n",
    "data =data.drop(columns=['Log Mode', 'Log Freq', 'Timestamp'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the raw data\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "data.plot(subplots=True, layout=(len(data.columns),1),figsize=(40,100))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that at the beginning and end there is a lot of noise, probably due to the movements necessary to start and end the experiment. It is proposed to discard the data of the beginning and end, but they are left for a greater generality of the code.\n",
    "\n",
    "You can see that in some columns, especially in GyroX, you can practically see the beats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STATISTICAL ANALYSIS <br>\n",
    "Performed by Selen Arsalan and Dyutideepta Banerjee <br>\n",
    "Mean:sum of all samples divided by the total number of samples. <br>\n",
    "Median:The median is the middle value in a dataset when ordered from largest to smallest or smallest to largest. <br>\n",
    "Variance: In statistics, the variance is a measure of how far individual (numeric) values in a dataset are from the mean or average value. <br> \n",
    "The variance is often used to quantify spread or dispersion. Spread is a characteristic of a sample or population that describes how much variability there is in it. <br>\n",
    "Standard deviation: In statistics, standard deviation is the measure of dispersion of a set of data from its mean. It measures the absolute variability of a distribution; the higher the dispersion, the greater is the standard deviation and greater will be the magnitude of the deviation of the value from their mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STATISTICAL ANALYSIS FOR MANDATORY DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_median=(data.loc[:,\"AccX\"]).median(axis = 0)\n",
    "ax_mean=(data.loc[:,\"AccX\"]).mean(axis = 0)\n",
    "ax_var=(data.loc[:,\"AccX\"]).var(axis = 0)\n",
    "ax_std=(data.loc[:,\"AccX\"]).std(axis = 0)\n",
    "ax_25=(data.loc[:,\"AccX\"]).quantile(0.25)\n",
    "ax_75=(data.loc[:,\"AccX\"]).quantile(0.75)\n",
    "\n",
    "ay_median=(data.loc[:,\"AccY\"]).median(axis = 0)\n",
    "ay_mean=(data.loc[:,\"AccY\"]).mean(axis = 0)\n",
    "ay_var=(data.loc[:,\"AccY\"]).var(axis = 0)\n",
    "ay_std=(data.loc[:,\"AccY\"]).std(axis = 0)\n",
    "ay_25=(data.loc[:,\"AccY\"]).quantile(0.25)\n",
    "ay_75=(data.loc[:,\"AccY\"]).quantile(0.75)\n",
    "\n",
    "az_median=(data.loc[:,\"AccZ\"]).median(axis = 0)\n",
    "az_mean=(data.loc[:,\"AccZ\"]).mean(axis = 0)\n",
    "az_var=(data.loc[:,\"AccZ\"]).var(axis = 0)\n",
    "az_std=(data.loc[:,\"AccZ\"]).std(axis = 0)\n",
    "az_25=(data.loc[:,\"AccZ\"]).quantile(0.25)\n",
    "az_75=(data.loc[:,\"AccZ\"]).quantile(0.75)\n",
    "print(\"AccX mean=\",ax_mean,\"AccY mean=\",ay_mean,\"AccZ mean=\",az_mean,'\\n',\n",
    "      \"AccX median=\",ax_median,\"AccY median=\",ay_median,\"AccZ median=\",az_median,'\\n',\n",
    "      \"AccX variance=\",ax_var,\"AccY variance=\",ay_var,\"AccZ variance=\",az_var,'\\n',\n",
    "      \"AccX standard dev.=\",ax_std,\"AccY standard dev.=\",ay_std,\"AccZ standard dev.=\",az_std,'\\n'\n",
    "      ,\"AccX 25 percentile=\",ax_25,\"AccY 25 percentile=\",ay_25,\"AccZ 25 percentile=\",az_25,\n",
    "      \"AccX 75 percentile=\",ax_75,\"AccY 75 percentile=\",ay_75,\"AccZ 75 percentile=\",az_75,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_median=(data.loc[:,\"GyroX\"]).median(axis = 0)\n",
    "gx_mean=(data.loc[:,\"GyroX\"]).mean(axis = 0)\n",
    "gx_var=(data.loc[:,\"GyroX\"]).var(axis = 0)\n",
    "gx_std=(data.loc[:,\"GyroX\"]).std(axis = 0)\n",
    "gx_25=(data.loc[:,\"GyroX\"]).quantile(0.25)\n",
    "gx_75=(data.loc[:,\"GyroX\"]).quantile(0.75)\n",
    "\n",
    "gy_median=(data.loc[:,\"GyroY\"]).median(axis = 0)\n",
    "gy_mean=(data.loc[:,\"GyroY\"]).mean(axis = 0)\n",
    "gy_var=(data.loc[:,\"GyroY\"]).var(axis = 0)\n",
    "gy_std=(data.loc[:,\"GyroY\"]).std(axis = 0)\n",
    "gy_25=(data.loc[:,\"GyroY\"]).quantile(0.25)\n",
    "gy_75=(data.loc[:,\"GyroY\"]).quantile(0.75)\n",
    "\n",
    "gz_median=(data.loc[:,\"GyroZ\"]).median(axis = 0)\n",
    "gz_mean=(data.loc[:,\"GyroZ\"]).mean(axis = 0)\n",
    "gz_var=(data.loc[:,\"GyroZ\"]).var(axis = 0)\n",
    "gz_std=(data.loc[:,\"GyroZ\"]).std(axis = 0)\n",
    "gz_25=(data.loc[:,\"GyroZ\"]).quantile(0.25)\n",
    "gz_75=(data.loc[:,\"GyroZ\"]).quantile(0.75)\n",
    "print(\"GyroX mean=\",gx_mean,\"GyroY mean=\",gy_mean,\"GyroZ mean=\",gz_mean,'\\n',\n",
    "      \"GyroX median=\",gx_median,\"GyroY median=\",gy_median,\"GyroZ median=\",gz_median,'\\n',\n",
    "      \"GyroX variance=\",gx_var,\"GyroY variance=\",gy_var,\"GyroZ variance=\",gz_var,'\\n',\n",
    "      \"GyroX standard dev.=\",gx_std,\"GyroY standard dev.=\",gy_std,\"GyroZ standard dev.=\",gz_std,'\\n'\n",
    "      ,\"GyroX 25 percentile=\",gx_25,\"GyroY 25 percentile=\",gy_25,\"GyroZ 25 percentile=\",gz_25,\n",
    "      \"GyroX 75 percentile=\",gx_75,\"GyroY 75 percentile=\",gy_75,\"GyroZ 75 percentile=\",gz_75,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_median=(data.loc[:,\"MagnX\"]).median(axis = 0)\n",
    "mx_mean=(data.loc[:,\"MagnX\"]).mean(axis = 0)\n",
    "mx_var=(data.loc[:,\"MagnX\"]).var(axis = 0)\n",
    "mx_std=(data.loc[:,\"MagnX\"]).std(axis = 0)\n",
    "mx_25=(data.loc[:,\"MagnX\"]).quantile(0.25)\n",
    "mx_75=(data.loc[:,\"MagnX\"]).quantile(0.75)\n",
    "\n",
    "my_median=(data.loc[:,\"MagnY\"]).median(axis = 0)\n",
    "my_mean=(data.loc[:,\"MagnY\"]).mean(axis = 0)\n",
    "my_var=(data.loc[:,\"MagnY\"]).var(axis = 0)\n",
    "my_std=(data.loc[:,\"MagnY\"]).std(axis = 0)\n",
    "my_25=(data.loc[:,\"MagnY\"]).quantile(0.25)\n",
    "my_75=(data.loc[:,\"MagnY\"]).quantile(0.75)\n",
    "\n",
    "mz_median=(data.loc[:,\"MagnZ\"]).median(axis = 0)\n",
    "mz_mean=(data.loc[:,\"MagnZ\"]).mean(axis = 0)\n",
    "mz_var=(data.loc[:,\"MagnZ\"]).var(axis = 0)\n",
    "mz_std=(data.loc[:,\"MagnZ\"]).std(axis = 0)\n",
    "mz_25=(data.loc[:,\"MagnZ\"]).quantile(0.25)\n",
    "mz_75=(data.loc[:,\"MagnZ\"]).quantile(0.75)\n",
    "\n",
    "print(\"MagnX mean=\",mx_mean,\"MagnY mean=\",my_mean,\"MagnZ mean=\",mz_mean,'\\n',\n",
    "      \"MagnX median=\",mx_median,\"MagnY median=\",my_median,\"MagnZ median=\",mz_median,'\\n',\n",
    "      \"MagnX variance=\",mx_var,\"MagnY variance=\",my_var,\"MagnZ variance=\",mz_var,'\\n',\n",
    "      \"MagnX standard dev.=\",mx_std,\"MagnY standard dev.=\",my_std,\"MagnZ standard dev.=\",mz_std,'\\n'\n",
    "      ,\"MagnX 25 percentile=\",mx_25,\"MagnY 25 percentile=\",my_25,\"MagnZ 25 percentile=\",mz_25,\n",
    "      \"MagnX 75 percentile=\",mx_75,\"MagnY 75 percentile=\",my_75,\"MagnZ 75 percentile=\",mz_75,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time_vec1\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.subplot(131)\n",
    "plt.title('Mean and Median of AccX/Y/Z', size=100)\n",
    "plt.xlabel('Value', size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.axvline(ax_mean, color='g', linestyle=\"-\",linewidth=5.0)\n",
    "plt.axvline(ay_mean, color='b', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(az_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(ax_median, color='g', linestyle=\"--\",linewidth=5.0)\n",
    "plt.axvline(ay_median, color='b', linestyle='--',linewidth=5.0)\n",
    "plt.axvline(az_median, color='r', linestyle='--',linewidth=5.0)\n",
    "print('Outcome: mean>median :positively skewed distribution.')\n",
    "#A positively skewed distribution means that a majority of the observations are rather small relative to the rest of the distribution. \n",
    "plt.subplot(132)\n",
    "# plt.figure(figsize=(60,40))\n",
    "plt.title('Mean and Median of GyroX/Y/Z', size=100)\n",
    "plt.xlabel('Value', size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.axvline(gx_mean, color='g', linestyle=\"-\",linewidth=5.0)\n",
    "plt.axvline(gy_mean, color='b', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(gz_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(gx_median, color='g', linestyle=\"--\",linewidth=5.0)\n",
    "plt.axvline(gy_median, color='b', linestyle='--',linewidth=5.0)\n",
    "plt.axvline(gz_median, color='r', linestyle='--',linewidth=5.0)\n",
    "print('Outcome: medians and mediums are similar, it is kind of symmetrical distributed.')\n",
    "plt.subplot(133)\n",
    "# plt.figure(figsize=(60,40))\n",
    "plt.title('Mean and Median of MagnX/Y/Z', size=100)\n",
    "plt.xlabel('Value', size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.axvline(mx_mean, color='g', linestyle=\"-\",linewidth=5.0)\n",
    "plt.axvline(my_mean, color='b', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(mz_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(mx_median, color='g', linestyle=\"--\",linewidth=5.0)\n",
    "plt.axvline(my_median, color='b', linestyle='--',linewidth=5.0)\n",
    "plt.axvline(mz_median, color='r', linestyle='--',linewidth=5.0)\n",
    "print('Outcome: median>mean : negatively skewed distribution')\n",
    "\n",
    "\n",
    "#The standard deviation is a measure of spread. \n",
    "#We use it as a measure of spread when we use the mean as a measure of center.\n",
    "x = data['AccX'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('AccX',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.axhline(ax_mean, color='g', linestyle=\"-\",linewidth=5.0)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is big (232) and the spread is big.')\n",
    "\n",
    "\n",
    "x = data['AccY'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('AccY',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.axhline(ay_mean, color='b', linestyle='-',linewidth=5.0)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is not too big (62) and the spread is big.')\n",
    "\n",
    "x = data['AccZ'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('AccZ',size=100)\n",
    "plt.axhline(az_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is big (215) and the spread is big.')\n",
    "\n",
    "x = data['GyroX'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('GyroX',size=100)\n",
    "plt.axhline(gx_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is low (13) and the spread is big. Mean and Median are similar.')\n",
    "\n",
    "x = data['GyroY'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('GyroY',size=100)\n",
    "plt.axhline(gy_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is low (17) and the spread is big.')\n",
    "\n",
    "\n",
    "x = data['GyroZ'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('GyroZ',size=100)\n",
    "plt.axhline(gz_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is low (10) and the spread is big.')\n",
    "\n",
    "\n",
    "x = data['MagnX'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('MagnX',size=100)\n",
    "plt.axhline(mx_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is low (67) and the spread is big.')\n",
    "\n",
    "x = data['MagnY'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('MagnY',size=100)\n",
    "plt.axhline(my_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is low (16) and the spread is big.')\n",
    "\n",
    "x = data['MagnZ'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('MagnZ',size=100)\n",
    "plt.axhline(mz_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is low (123) and the spread is big.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation:<br>\n",
    "Correlation analysis gives us the linear relationship between two variables. <br>\n",
    "The correlation coefficient between two variables is a statistical measure of the strength of the relationship between the relative movements of two variables.\n",
    "A correlation of -1.0 shows a perfect negative correlation, while a correlation of 1.0 shows a perfect positive correlation. A correlation of 0.0 shows no linear relationship between the movement of the two variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_corr = data.loc[:,[\"AccX\",\"AccY\",\"AccZ\",\"GyroX\",\"GyroY\",\"GyroZ\",\"MagnX\",\"MagnY\",\"MagnZ\"]]\n",
    "data1_corr.corr(method='pearson', min_periods=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset we see that Gyroscope of X, Y and Z have close to zero correlation coefficient with the other variables. \n",
    "This means that Gyroscope values are least dependent on the other variables making it reliable to use for analysis. \n",
    "With low correlation values and small deviation values, we assume that Gyroscope columns are the best for use of our purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STATISTICAL ANALYSIS FOR OPTIONAL DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"1_Stave_supine_static.txt\"#\"C:/Users/Xabier Galar/High Level project/LCP_projects_Y3-Group25/1_Stave_supine_static.txt\"\n",
    "data2=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "time_step2 = 1/100\n",
    "index = data2.index\n",
    "number_of_rows2 = len(index)\n",
    "time_vec2 = np.arange(0, number_of_rows2 * time_step2, time_step2)\n",
    "data2.insert(0, 'new_seconds', time_vec2)\n",
    "data2 =data2.drop(columns=['Log Mode', 'Log Freq', 'Timestamp'])\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_median=(data2.loc[:,\"AccX\"]).median(axis = 0)\n",
    "ax_mean=(data2.loc[:,\"AccX\"]).mean(axis = 0)\n",
    "ax_var=(data2.loc[:,\"AccX\"]).var(axis = 0)\n",
    "ax_std=(data2.loc[:,\"AccX\"]).std(axis = 0)\n",
    "ax_25=(data2.loc[:,\"AccX\"]).quantile(0.25)\n",
    "ax_75=(data2.loc[:,\"AccX\"]).quantile(0.75)\n",
    "\n",
    "ay_median=(data2.loc[:,\"AccY\"]).median(axis = 0)\n",
    "ay_mean=(data2.loc[:,\"AccY\"]).mean(axis = 0)\n",
    "ay_var=(data2.loc[:,\"AccY\"]).var(axis = 0)\n",
    "ay_std=(data2.loc[:,\"AccY\"]).std(axis = 0)\n",
    "ay_25=(data2.loc[:,\"AccY\"]).quantile(0.25)\n",
    "ay_75=(data2.loc[:,\"AccY\"]).quantile(0.75)\n",
    "\n",
    "az_median=(data2.loc[:,\"AccZ\"]).median(axis = 0)\n",
    "az_mean=(data2.loc[:,\"AccZ\"]).mean(axis = 0)\n",
    "az_var=(data2.loc[:,\"AccZ\"]).var(axis = 0)\n",
    "az_std=(data2.loc[:,\"AccZ\"]).std(axis = 0)\n",
    "az_25=(data2.loc[:,\"AccZ\"]).quantile(0.25)\n",
    "az_75=(data2.loc[:,\"AccZ\"]).quantile(0.75)\n",
    "print(\"AccX mean=\",ax_mean,\"AccY mean=\",ay_mean,\"AccZ mean=\",az_mean,'\\n',\n",
    "      \"AccX median=\",ax_median,\"AccY median=\",ay_median,\"AccZ median=\",az_median,'\\n',\n",
    "      \"AccX variance=\",ax_var,\"AccY variance=\",ay_var,\"AccZ variance=\",az_var,'\\n',\n",
    "      \"AccX standard dev.=\",ax_std,\"AccY standard dev.=\",ay_std,\"AccZ standard dev.=\",az_std,'\\n'\n",
    "      ,\"AccX 25 percentile=\",ax_25,\"AccY 25 percentile=\",ay_25,\"AccZ 25 percentile=\",az_25,\n",
    "      \"AccX 75 percentile=\",ax_75,\"AccY 75 percentile=\",ay_75,\"AccZ 75 percentile=\",az_75,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx_median=(data2.loc[:,\"GyroX\"]).median(axis = 0)\n",
    "gx_mean=(data2.loc[:,\"GyroX\"]).mean(axis = 0)\n",
    "gx_var=(data2.loc[:,\"GyroX\"]).var(axis = 0)\n",
    "gx_std=(data2.loc[:,\"GyroX\"]).std(axis = 0)\n",
    "gx_25=(data2.loc[:,\"GyroX\"]).quantile(0.25)\n",
    "gx_75=(data2.loc[:,\"GyroX\"]).quantile(0.75)\n",
    "\n",
    "gy_median=(data2.loc[:,\"GyroY\"]).median(axis = 0)\n",
    "gy_mean=(data2.loc[:,\"GyroY\"]).mean(axis = 0)\n",
    "gy_var=(data2.loc[:,\"GyroY\"]).var(axis = 0)\n",
    "gy_std=(data2.loc[:,\"GyroY\"]).std(axis = 0)\n",
    "gy_25=(data2.loc[:,\"GyroY\"]).quantile(0.25)\n",
    "gy_75=(data2.loc[:,\"GyroY\"]).quantile(0.75)\n",
    "\n",
    "gz_median=(data2.loc[:,\"GyroZ\"]).median(axis = 0)\n",
    "gz_mean=(data2.loc[:,\"GyroZ\"]).mean(axis = 0)\n",
    "gz_var=(data2.loc[:,\"GyroZ\"]).var(axis = 0)\n",
    "gz_std=(data2.loc[:,\"GyroZ\"]).std(axis = 0)\n",
    "gz_25=(data2.loc[:,\"GyroZ\"]).quantile(0.25)\n",
    "gz_75=(data2.loc[:,\"GyroZ\"]).quantile(0.75)\n",
    "print(\"GyroX mean=\",gx_mean,\"GyroY mean=\",gy_mean,\"GyroZ mean=\",gz_mean,'\\n',\n",
    "      \"GyroX median=\",gx_median,\"GyroY median=\",gy_median,\"GyroZ median=\",gz_median,'\\n',\n",
    "      \"GyroX variance=\",gx_var,\"GyroY variance=\",gy_var,\"GyroZ variance=\",gz_var,'\\n',\n",
    "      \"GyroX standard dev.=\",gx_std,\"GyroY standard dev.=\",gy_std,\"GyroZ standard dev.=\",gz_std,'\\n'\n",
    "      ,\"GyroX 25 percentile=\",gx_25,\"GyroY 25 percentile=\",gy_25,\"GyroZ 25 percentile=\",gz_25,\n",
    "      \"GyroX 75 percentile=\",gx_75,\"GyroY 75 percentile=\",gy_75,\"GyroZ 75 percentile=\",gz_75,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_median=(data2.loc[:,\"MagnX\"]).median(axis = 0)\n",
    "mx_mean=(data2.loc[:,\"MagnX\"]).mean(axis = 0)\n",
    "mx_var=(data2.loc[:,\"MagnX\"]).var(axis = 0)\n",
    "mx_std=(data2.loc[:,\"MagnX\"]).std(axis = 0)\n",
    "mx_25=(data2.loc[:,\"MagnX\"]).quantile(0.25)\n",
    "mx_75=(data2.loc[:,\"MagnX\"]).quantile(0.75)\n",
    "\n",
    "my_median=(data2.loc[:,\"MagnY\"]).median(axis = 0)\n",
    "my_mean=(data2.loc[:,\"MagnY\"]).mean(axis = 0)\n",
    "my_var=(data2.loc[:,\"MagnY\"]).var(axis = 0)\n",
    "my_std=(data2.loc[:,\"MagnY\"]).std(axis = 0)\n",
    "my_25=(data2.loc[:,\"MagnY\"]).quantile(0.25)\n",
    "my_75=(data2.loc[:,\"MagnY\"]).quantile(0.75)\n",
    "\n",
    "mz_median=(data2.loc[:,\"MagnZ\"]).median(axis = 0)\n",
    "mz_mean=(data2.loc[:,\"MagnZ\"]).mean(axis = 0)\n",
    "mz_var=(data2.loc[:,\"MagnZ\"]).var(axis = 0)\n",
    "mz_std=(data2.loc[:,\"MagnZ\"]).std(axis = 0)\n",
    "mz_25=(data2.loc[:,\"MagnZ\"]).quantile(0.25)\n",
    "mz_75=(data2.loc[:,\"MagnZ\"]).quantile(0.75)\n",
    "\n",
    "print(\"MagnX mean=\",mx_mean,\"MagnY mean=\",my_mean,\"MagnZ mean=\",mz_mean,'\\n',\n",
    "      \"MagnX median=\",mx_median,\"MagnY median=\",my_median,\"MagnZ median=\",mz_median,'\\n',\n",
    "      \"MagnX variance=\",mx_var,\"MagnY variance=\",my_var,\"MagnZ variance=\",mz_var,'\\n',\n",
    "      \"MagnX standard dev.=\",mx_std,\"MagnY standard dev.=\",my_std,\"MagnZ standard dev.=\",mz_std,'\\n'\n",
    "      ,\"MagnX 25 percentile=\",mx_25,\"MagnY 25 percentile=\",my_25,\"MagnZ 25 percentile=\",mz_25,\n",
    "      \"MagnX 75 percentile=\",mx_75,\"MagnY 75 percentile=\",my_75,\"MagnZ 75 percentile=\",mz_75,\n",
    "      \n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time_vec2\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.subplot(131)\n",
    "plt.title('Mean and Median of AccX/Y/Z', size=100)\n",
    "plt.xlabel('Value', size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.axvline(ax_mean, color='g', linestyle=\"-\",linewidth=5.0)\n",
    "plt.axvline(ay_mean, color='b', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(az_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(ax_median, color='g', linestyle=\"--\",linewidth=5.0)\n",
    "plt.axvline(ay_median, color='b', linestyle='--',linewidth=5.0)\n",
    "plt.axvline(az_median, color='r', linestyle='--',linewidth=5.0)\n",
    "print('Outcome: mean<medium: positively skewed distribution')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.title('Mean and Median of GyroX/Y/Z', size=100)\n",
    "plt.xlabel('Value', size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.axvline(gx_mean, color='g', linestyle=\"-\",linewidth=5.0)\n",
    "plt.axvline(gy_mean, color='b', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(gz_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(gx_median, color='g', linestyle=\"--\",linewidth=5.0)\n",
    "plt.axvline(gy_median, color='b', linestyle='--',linewidth=5.0)\n",
    "plt.axvline(gz_median, color='r', linestyle='--',linewidth=5.0)\n",
    "print('Outcome: medians and mediums are similar, it is kind of symmetrical distributed.')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.title('Mean and Median of MagnX/Y/Z', size=100)\n",
    "plt.xlabel('Value', size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.axvline(mx_mean, color='g', linestyle=\"-\",linewidth=5.0)\n",
    "plt.axvline(my_mean, color='b', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(mz_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.axvline(mx_median, color='g', linestyle=\"--\",linewidth=5.0)\n",
    "plt.axvline(my_median, color='b', linestyle='--',linewidth=5.0)\n",
    "plt.axvline(mz_median, color='r', linestyle='--',linewidth=5.0)\n",
    "print('Outcome: mean<medium: positively skewed distribution')\n",
    "\n",
    "x = data2['AccX'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('AccX',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.axhline(ax_mean, color='g', linestyle=\"-\",linewidth=5.0)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is big (172) and the spread is big.')\n",
    "\n",
    "x = data2['AccY'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('AccY',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.axhline(ay_mean, color='b', linestyle='-',linewidth=5.0)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is big (182) and the spread is big.')\n",
    "\n",
    "x = data2['AccZ'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('AccZ',size=100)\n",
    "plt.axhline(az_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is big (485) and the spread is big.')\n",
    "\n",
    "x = data2['GyroX'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('GyroX',size=100)\n",
    "plt.axhline(gx_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is not too  big (81) and the spread is medium size.')\n",
    "\n",
    "x = data2['GyroY'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('GyroY',size=100)\n",
    "plt.axhline(gy_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is not too big (88) and the spread is medium size.')\n",
    "\n",
    "x = data2['GyroZ'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('GyroZ',size=100)\n",
    "plt.axhline(gz_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is not too big (53) and the spread is medium size.')\n",
    "\n",
    "x = data2['MagnX'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('MagnX',size=100)\n",
    "plt.axhline(mx_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is not too big (93) and the spread is medium size.')\n",
    "\n",
    "x = data2['MagnY'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('MagnY',size=100)\n",
    "plt.axhline(my_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is not too big (68) and the spread is medium.')\n",
    "\n",
    "x = data2['MagnZ'] \n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('MagnZ',size=100)\n",
    "plt.axhline(mz_mean, color='r', linestyle='-',linewidth=5.0)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.show()\n",
    "print('standard deviation is not  big (235) and the spread is big.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation\n",
    "data2_corr = data2.loc[:,[\"AccX\",\"AccY\",\"AccZ\",\"GyroX\",\"GyroY\",\"GyroZ\",\"MagnX\",\"MagnY\",\"MagnZ\"]]\n",
    "data2_corr.corr(method='pearson', min_periods=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again, looking at the small values of Gyroscope X, Y and Z and backing with the previous statistical analysis proving smaller deviations for Gyroscopic data points, we assume that Gyroscope columns are most suitable for our data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to analysis of Mandatory Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple FFT\n",
    "\n",
    "def plotFFT(df, T):\n",
    "    index = df.index\n",
    "    number_of_rows = len(index)\n",
    "    N = number_of_rows\n",
    "    x = np.linspace(0.0, N*T, N, endpoint=False)\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    f, ax = plt.subplots(int(math.ceil((len(df.columns)-1)/4)),4, figsize=(15,15))\n",
    "    ax = ax.ravel()\n",
    "    \n",
    "    for i in range(0, len(df.columns)-1, 1):\n",
    "        y = df.iloc[:, i+1].to_numpy()\n",
    "        ax[i].set_title(df.columns[i+1])\n",
    "        yf = fft(y)\n",
    "        xf = fftfreq(N, T)[:N//2]\n",
    "        ax[i].plot(xf, 2.0/N * np.abs(yf[0:N//2]))\n",
    "        ax[i].set_xlim(-1,30)\n",
    "        ax[i].grid()\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFFT(data, time_step1)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very large peak at 0Hz in some of the columns due to offset, it must be removed to better appreciate the FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove offset from the signals\n",
    "def offsetRemove(df):\n",
    "    df2 = pd.DataFrame(df)\n",
    "    for i in range(1, len(df2.columns), 1):\n",
    "        while np.mean(df2.iloc[:, i].to_numpy()) < -0.2 or np.mean(df2.iloc[:, i].to_numpy()) > 0.2:\n",
    "            df2.iloc[:, i]= df2.iloc[:, i] - np.mean(df2.iloc[:, i].to_numpy())\n",
    "    return df2\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFFT(offsetRemove(data), time_step1)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All signals have a peak very close to 0Hz, probably heart beats. Remember that the usual Bpm is normally between 40 and 100 (0.67 - 1.67 Hz).\n",
    "\n",
    "In order to stay with this range of frequencies and discard the others, we proceed with a filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions to perform the filtering\n",
    "\n",
    "# Obtain the parameters of Butterworth Bandpass filter\n",
    "def butter_bandpass(lowcut, highcut, fs, order=3):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "# Apply the filter\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "# apply the filter and plot the original ande the filtered data\n",
    "def butterBandFilterAndPlot(data, lowcut, highcut, fs, order,t):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(t, data, label='Noisy signal')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    y = butter_bandpass_filter(data, lowcut, highcut, fs, order)\n",
    "    plt.plot(t, y, label='Filtered signal')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    return y\n",
    "\n",
    "# Obtain the frequency response of a Butterworth Bandpass filter\n",
    "def bandFreqResponse(lowcut, highcut, fs, order):    \n",
    "    plt.figure()\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    w, h = freqz(b, a, worN=2000)\n",
    "    plt.plot((fs * 0.5 / np.pi) * w, abs(h), 'b')\n",
    "\n",
    "    plt.plot([0, 0.5 * fs], [np.sqrt(0.5), np.sqrt(0.5)],\n",
    "             '--')\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Gain')\n",
    "    plt.title(\"Butterworth Bandpass order %d FR\" % order)\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0,highcut*3)\n",
    "    plt.xticks(np.arange(0, int(highcut*3), step=0.5), rotation = 45)\n",
    "    plt.show()\n",
    "\n",
    "# Obtain the parameters of Butterworth Lowpas filter\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "# Apply the filter\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "    \n",
    "# apply the filter and plot the original ande the filtered data    \n",
    "def butterLowFilterAndPlot(data, highcut, fs, order,t):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(t, data, label='Noisy signal')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    y = butter_lowpass_filter(data, highcut, fs, order)\n",
    "    plt.plot(t, y, label='Filtered signal')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "    return y\n",
    "\n",
    "# Obtain the frequency response of the Butterworth Lowpas filter\n",
    "def lowFreqResponse(cutoff, fs, order):\n",
    "    # Get the filter coefficients so we can check its frequency response.\n",
    "    b, a = butter_lowpass(cutoff, fs, order)\n",
    "    # Plot the frequency response.\n",
    "    w, h = freqz(b, a, worN=8000)\n",
    "    plt.figure()\n",
    "    plt.plot(0.5*fs*w/np.pi, np.abs(h), 'b')\n",
    "    plt.plot(cutoff, 0.5*np.sqrt(2), 'ko')\n",
    "    plt.axvline(cutoff, color='k')\n",
    "    plt.xlim(0, 0.5*fs)\n",
    "    plt.title(\"Lowpass order %d FR\" %order)\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.ylabel('Gain')\n",
    "    plt.grid()\n",
    "    plt.xlim(0,cutoff*3)\n",
    "    plt.xticks(np.arange(0, int(cutoff*3), step=0.5), rotation = 45)\n",
    "    plt.show()\n",
    "    \n",
    "# Create a new dataframe with applying the bandapss filter, and combine some of those columns\n",
    "def createFilteredDF(df,lowcut, highcut, fs, order):\n",
    "\n",
    "    filtered = pd.DataFrame(columns=df.columns)\n",
    "    filtered['new_seconds']=df['new_seconds']\n",
    "    for i in range(0, len(df.columns)-1, 1):\n",
    "        x = df.iloc[:, i+1].to_numpy()\n",
    "        y = butter_bandpass_filter(x, lowcut, highcut, fs, order)\n",
    "        filtered.iloc[:, i+1] = y\n",
    "\n",
    "    index = filtered.index\n",
    "    number_of_rows2 = len(index)\n",
    "#     Combine the Acc columns\n",
    "    y = np.zeros([number_of_rows2,])\n",
    "    for i in [1,2,3]:\n",
    "        x = filtered.iloc[:, i].to_numpy()\n",
    "        y = y + butter_bandpass_filter(x, lowcut, highcut, fs, order)\n",
    "    filtered['Acc'] = y\n",
    "#     Combine the Gyro columns\n",
    "    y = np.zeros([number_of_rows2,]) \n",
    "    for i in [4,5,6]:\n",
    "        x = filtered.iloc[:, i].to_numpy()\n",
    "        y = y + butter_bandpass_filter(x, lowcut, highcut, fs, order)\n",
    "    filtered['Gyro'] = y\n",
    "#     Combine the Magn columns\n",
    "    y = np.zeros([number_of_rows2,])\n",
    "    for i in [7,8,9]:\n",
    "        x = filtered.iloc[:, i].to_numpy()\n",
    "        y = y + butter_bandpass_filter(x, lowcut, highcut, fs, order)\n",
    "    filtered['Magn'] = y\n",
    "# Combine all the columns\n",
    "    y = np.zeros([number_of_rows2,])\n",
    "    for i in range(1, len(df.columns)-1,1):\n",
    "        x = filtered.iloc[:, i].to_numpy()\n",
    "        y = y + butter_bandpass_filter(x, lowcut, highcut, fs, order)\n",
    "    filtered['All'] = y\n",
    "    filtered\n",
    "    return filtered\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter requirements.\n",
    "order = 8\n",
    "fs = 200       # sample rate, Hz\n",
    "lowcut = 40/60  \n",
    "highcut = 100/60\n",
    "lowFreqResponse(250/60, fs, order)\n",
    "bandFreqResponse(lowcut,highcut,fs,3)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering some data, it works pretty well with some axes\n",
    "fs = 200.0          #Sample frequency\n",
    "lowcut = 40/60      \n",
    "highcut = 100/60\n",
    "order=2\n",
    "%matplotlib inline\n",
    "t = time_vec1\n",
    "y =butterBandFilterAndPlot(data['AccZ'].to_numpy(),lowcut, highcut, fs, 3, t)\n",
    "_ = butterLowFilterAndPlot(data['AccZ'].to_numpy(), 200/60, fs, 8, t)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F analyses on mandatory data(x,y,and z) by Ali\n",
    "\n",
    "fft_man = fftpack.fft(list(data['AccZ'].to_numpy()))\n",
    "power_man = np.abs(fft_man)\n",
    "sample_freq = fftpack.fftfreq(number_of_rows1, time_step1)\n",
    "\n",
    "pos_mask = np.where(np.logical_and(sample_freq > lowcut, sample_freq < highcut))\n",
    "# pos_mask = np.where(sample_freq > 0.15)\n",
    "freqs = sample_freq[pos_mask]\n",
    "peak_freq = freqs[power_man[pos_mask].argmax()]\n",
    "spectrum = power_man[pos_mask]\n",
    "\n",
    "antitransformed_man = fftpack.ifft(spectrum)\n",
    "# beats_man , _man = find_peaks(antitransformed_man, threshold=24)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.linspace(0,75,len(freqs)), np.abs(antitransformed_man), label='Filtered signal')\n",
    "# plt.plot(np.linspace(0,75,len(beats_man)), antitransformed_man[beats_man])\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylim(-10,10000)\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few tests it is concluded that the best filter is the bandpass butterworth filter of order 3.\n",
    "\n",
    "Now we proceed to identify the peaks that represent the pulsations.\n",
    "It is done by two methods, with the specific heartpy library and with the sipy function find_peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proccesing the data with the library\n",
    "wd, m = hp.process(y, sample_rate = 200.0)\n",
    "plt.figure(figsize=(12,4))\n",
    "hp.plotter(wd, m)\n",
    "#display measures computed\n",
    "for measure in m.keys():\n",
    "    print('%s: %f' %(measure, m[measure]))\n",
    "    \n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procces the data \"by hand\"\n",
    "peaks, _ = find_peaks(y, distance=100)\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(data['new_seconds'], y)\n",
    "plt.plot(data['new_seconds'][peaks], y[peaks], \"x\")\n",
    "plt.xlabel('Time (s)')\n",
    "plt.show()\n",
    "print('Average BPM:')\n",
    "print(1/((peaks[-1]-peaks[0])/len(peaks)*0.005)*60)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a df, filters and plots all columns finding peaks\n",
    "def rawPeaks(df, distance, lowcut, highcut, fs, order):\n",
    "    f, ax = plt.subplots(len(df.columns)-1,1, figsize=(15,40))\n",
    "    for i in range(0, len(df.columns)-1, 1):\n",
    "\n",
    "        x = df.iloc[:, i+1].to_numpy()\n",
    "        ax[i].set_title(data.columns[i+1])\n",
    "        ax[i].plot(df['new_seconds'],x, 'c', label= 'Original')\n",
    "        y = butter_bandpass_filter(x, lowcut, highcut, fs, order)\n",
    "        ax[i].plot(df['new_seconds'], y, 'k', label= 'Filtered')\n",
    "        peaks, _ = find_peaks(y, distance=distance)\n",
    "        ax[i].plot(df['new_seconds'],y)\n",
    "        ax[i].plot(df['new_seconds'][peaks], y[peaks], \"x\")\n",
    "        ax[i].text(0.5, 0.1,'Detected peacks : %d' %len(peaks), horizontalalignment='center', verticalalignment='center', transform = ax[i].transAxes)\n",
    "        ax[i].legend()\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 100\n",
    "lowcut= 40/60\n",
    "highcut =100/60 \n",
    "fs= 200\n",
    "order = 3\n",
    "rawPeaks(data, distance, lowcut, highcut, fs, order)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is seen that in all the data columns a fairly similar number of peaks can be counted, so it is decided to go ahead with all the data columns and also try some combinations of them.\n",
    "\n",
    "we proceed to create a new df with the filtered columns and some combinations of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut= 40/60\n",
    "highcut =100/60 \n",
    "fs= 200\n",
    "order = 3\n",
    "filtered1 = createFilteredDF(data, lowcut, highcut,fs, order)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a df, plots all columns and finds peaks\n",
    "def rawFilteredBPM(df, distance):\n",
    "    plt.rcParams.update({'font.size': 12})\n",
    "    plt.rc('xtick', labelsize=14) \n",
    "    plt.rc('ytick', labelsize=14) \n",
    "    f, ax = plt.subplots(len(df.columns)-1,1, figsize=(15,55))\n",
    "\n",
    "    for i in range(0, len(df.columns)-1, 1):\n",
    "        x = df.iloc[:, i+1].to_numpy()\n",
    "        ax[i].set_title(filtered1.columns[i+1])\n",
    "        ax[i].plot(df['new_seconds'], x, 'c', label= 'Filtered')\n",
    "        peaks, _ = find_peaks(x, distance=distance)\n",
    "        ax[i].plot(df['new_seconds'][peaks], x[peaks], \"xr\",)\n",
    "        ax[i].text(0.5, 0.1,'Detected peacks : %d' %len(peaks), horizontalalignment='center', verticalalignment='center', transform = ax[i].transAxes)\n",
    "        ax[i].legend()\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawFilteredBPM(filtered1, 100)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawFilteredBPM(data, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, it can be seen that a similar number of peaks are detected in all the columns, so it is decided to calculate the BPM in all of them and choose the median, to achieve a more stable result.\n",
    "\n",
    "Looking at the FT of the filtered data it can be seen that now only frequencies remain within the BPM range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFFT(filtered1, time_step1)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measureBeats(x, p, s, T):      #Given a column and the peaks of the column calculates\n",
    "    y = np.zeros_like(x)           #the BPM in an array of the lenght of the column\n",
    "    yb =0\n",
    "    n=0\n",
    "    p = np.pad(p,(0,s),'constant')\n",
    "    for i in range(len(x)):\n",
    "        if i == p[n]:\n",
    "            yb = 60/((p[n+s]-i)/s * T)\n",
    "            n = n+1\n",
    "        y[i]= yb\n",
    "    return y\n",
    "\n",
    "# Calculates the BPM of all the columns\n",
    "def BPM(df, distance, s, T, number_of_rows):\n",
    "    y = np.zeros([len(df.columns)-1, number_of_rows])\n",
    "    result = np.zeros([number_of_rows,])\n",
    "    \n",
    "    for i in range(0, len(df.columns)-1, 1):\n",
    "        x = df.iloc[:, i+1].to_numpy()\n",
    "        peaks, _ = find_peaks(x, distance=distance)\n",
    "        y[i,:] = measureBeats(x, peaks, s, T)\n",
    "    return y\n",
    "\n",
    "# Given all BPM of all columns calculates the median BPM and plots\n",
    "def medianBPMandPlot(bpm, filtered2):\n",
    "    result = ndimage.median_filter(bpm, size=(bpm.shape[0],1))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for i in range(bpm.shape[0]):\n",
    "        plt.plot(filtered2['new_seconds'], bpm[i,:], '--', label=filtered2.columns[i+1])\n",
    "    plt.plot(filtered2['new_seconds'], result[int((bpm.shape[0]-1)/2),:], 'r', linewidth=5, label= 'Median BPM')\n",
    "#     plt.ylim(30,55)\n",
    "    plt.title('BPM of all data and Median BPM')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.legend()\n",
    "    return result[int((bpm.shape[0]-1)/2),:]\n",
    "\n",
    "# Given all BPM of all columns calculates the median BPM\n",
    "def medianBPM(bpm, filtered2):\n",
    "    result = ndimage.median_filter(bpm, size=(bpm.shape[0],1))\n",
    "    return result[int((bpm.shape[0]-1)/2),:]\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcessDF(df, fs):\n",
    "    time_step = 1/fs\n",
    "    index = df.index\n",
    "    number_of_rows = len(index)\n",
    "    time_vec = np.arange(0, number_of_rows * time_step, time_step)\n",
    "    df.insert(0, 'new_seconds', time_vec)\n",
    "    df =df.drop(columns=['Log Mode', 'Log Freq', 'Timestamp'])\n",
    "    return df\n",
    "\n",
    "def findBPM(df, fs):\n",
    "    lowcut= 40/60\n",
    "    highcut =100/60 \n",
    "    order = 3\n",
    "    time_step = 1/fs\n",
    "    index = df.index\n",
    "    number_of_rows = len(index)\n",
    "    filtered = createFilteredDF(df, lowcut, highcut,fs, order)\n",
    "    bpm =BPM(filtered, 100, 10, time_step, number_of_rows)\n",
    "    y = medianBPMandPlot(bpm, filtered)\n",
    "    return y, filtered\n",
    "\n",
    "def rawVariances(df, bot, top):    \n",
    "    for i in range(0, len(df.columns)-1, 1):\n",
    "        y = df.iloc[:, i+1].to_numpy()\n",
    "        print(df.columns[i+1],\"  variance is %s\" %(round(statistics.pvariance(df.iloc[:, i+1][bot:top]),2)))\n",
    "\n",
    "def histoAndVariances(df, filtered, y, bot, top):\n",
    "    plt.figure()\n",
    "    _ = plt.hist(y[bot:top], bins=10)\n",
    "    print('No filtered')\n",
    "    rawVariances(df, bot, top)\n",
    "    print('Filtered')\n",
    "    rawVariances(filtered, bot, top)\n",
    "    print(\"Median variance is %s\" %(statistics.pvariance(y[2000:12000])))\n",
    "    \n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm =BPM(filtered1, 100, 10, time_step1, number_of_rows1)\n",
    "y = medianBPMandPlot(bpm, filtered1)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(y[2000:12000], bins=40)\n",
    "\n",
    "print('No filtered')\n",
    "rawVariances(data, 2000, 12000)\n",
    "print('Filtered')\n",
    "rawVariances(filtered1, 2000, 12000)\n",
    "print(\"Median variance is %s\" \n",
    "      %(statistics.pvariance(y[2000:12000])))\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawVariances(data, 2000,12000)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"1_Stave_supine_static.txt\"\n",
    "data2=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "data2\n",
    "time_step2 = 1/100\n",
    "index = data2.index\n",
    "number_of_rows2 = len(index)\n",
    "time_vec2 = np.arange(0, number_of_rows2 * time_step2, time_step2)\n",
    "data2.insert(0, 'new_seconds', time_vec2)\n",
    "data2 =data2.drop(columns=['Log Mode', 'Log Freq', 'Timestamp'])\n",
    "# data2\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the raw data\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "plt.figure()\n",
    "data2.plot(subplots=True, layout=(len(data2.columns),1),figsize=(40,100))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFFT(data2, time_step2)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFFT(offsetRemove(data), time_step1)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 100\n",
    "lowcut= 40/60\n",
    "highcut =100/60 \n",
    "fs= 100\n",
    "order = 3\n",
    "rawPeaks(data2, distance, lowcut, highcut, fs, order)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut= 40/60\n",
    "highcut =100/60 \n",
    "fs= 100\n",
    "order = 3\n",
    "filtered2 = createFilteredDF(data2, lowcut, highcut,fs, order)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawFilteredBPM(filtered2,100)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFFT(filtered2, time_step2)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpm =BPM(filtered2, 100, 10, time_step2, number_of_rows2)\n",
    "y = medianBPMandPlot(bpm, filtered2)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(y[500:4500], bins=40)\n",
    "print(\"Median BPM variance is %s\" \n",
    "      %(statistics.pvariance(y[500:4500]))) \n",
    "print(\"AccX filtered variance is %s\" \n",
    "      %(statistics.pvariance(bpm[0,500:4500]))) \n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"2_Mattress_supine.txt\"\n",
    "df=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "df =preProcessDF(df, 100)\n",
    "\n",
    "y, filtered = findBPM(df, 100)\n",
    "histoAndVariances(df, filtered, y,500, 4500)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"3_Subject_sitting_chair.txt\"\n",
    "df=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "df =preProcessDF(df, 100)\n",
    "\n",
    "y, filtered = findBPM(df, 100)\n",
    "histoAndVariances(df, filtered, y,500, 4500)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"4_Chest_sweater.txt\"\n",
    "df=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "df =preProcessDF(df, 100)\n",
    "\n",
    "y, filtered = findBPM(df, 100)\n",
    "histoAndVariances(df, filtered, y,500, 4500)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"5_Under_chair.txt\"\n",
    "df=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "df =preProcessDF(df, 100)\n",
    "\n",
    "y, filtered = findBPM(df, 100)\n",
    "histoAndVariances(df, filtered, y,500, 4500)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about the Respiratoy Rate?\n",
    "\n",
    "Same technique but with different cut frequencyes, normal RR in healthy person: 12 - 18 Respirations per minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter requirements.\n",
    "order = 3\n",
    "fs = 200       # sample rate, Hz\n",
    "lowcut = 12/60  \n",
    "highcut = 18/60\n",
    "lowFreqResponse(250/60, fs, order)\n",
    "bandFreqResponse(lowcut,highcut,fs, order)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = 100\n",
    "lowcut= 12/60\n",
    "highcut =18/60 \n",
    "fs= 200\n",
    "order = 3\n",
    "rawPeaks(data, distance, lowcut, highcut, fs, order)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut= 12/60\n",
    "highcut =18/60 \n",
    "fs= 200\n",
    "order = 3\n",
    "filtered_1 = createFilteredDF(data, lowcut, highcut,fs, order)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawFilteredBPM(filtered_1, 100)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotFFT(filtered_1, time_step1)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the BPM of all the columns\n",
    "def RR(df, distance, s, T, number_of_rows):\n",
    "    y = np.zeros([len(df.columns)-1, number_of_rows])\n",
    "    result = np.zeros([number_of_rows,])\n",
    "    \n",
    "    for i in range(0, len(df.columns)-1, 1):\n",
    "        x = df.iloc[:, i+1].to_numpy()\n",
    "        peaks, _ = find_peaks(x, distance=distance)\n",
    "        y[i,:] = measureBeats(x, peaks, s, T)\n",
    "    return y\n",
    "\n",
    "# Given all BPM of all columns calculates the median BPM and plots\n",
    "def medianRRandPlot(bpm, filtered2):\n",
    "    result = ndimage.median_filter(bpm, size=(bpm.shape[0],1))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for i in range(bpm.shape[0]):\n",
    "        plt.plot(filtered2['new_seconds'], bpm[i,:], '--', label=filtered2.columns[i+1])\n",
    "    plt.plot(filtered2['new_seconds'], result[int((bpm.shape[0]-1)/2),:], 'r', linewidth=5, label= 'Median BPM')\n",
    "#     plt.ylim(30,55)\n",
    "    plt.title('RR of all data and Median RR')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.legend()\n",
    "    return result[int((bpm.shape[0]-1)/2),:]\n",
    "\n",
    "# Given all BPM of all columns calculates the median BPM\n",
    "def medianRR(bpm, filtered2):\n",
    "    result = ndimage.median_filter(bpm, size=(bpm.shape[0],1))\n",
    "    return result[int((bpm.shape[0]-1)/2),:]\n",
    "\n",
    "def findRR(df, fs):\n",
    "    lowcut= 12/60\n",
    "    highcut =18/60 \n",
    "    order = 3\n",
    "    time_step = 1/fs\n",
    "    index = df.index\n",
    "    number_of_rows = len(index)\n",
    "    filtered = createFilteredDF(df, lowcut, highcut,fs, order)\n",
    "    bpm =RR(filtered, 100, 3, time_step, number_of_rows)\n",
    "    y = medianRRandPlot(bpm, filtered)\n",
    "    return y, filtered\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr =RR(filtered_1, 100, 3, time_step1, number_of_rows1)\n",
    "y = medianRRandPlot(rr, filtered_1)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histoAndVariances(data, filtered_1,y, 2000, 12000)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcut= 12/60\n",
    "highcut =18/60 \n",
    "fs= 100\n",
    "order = 3\n",
    "filtered_2 = createFilteredDF(data2, lowcut, highcut,fs, order)\n",
    "\n",
    "index = data2.index\n",
    "number_of_rows2 = len(index)\n",
    "\n",
    "rr =RR(filtered_2, 100, 3, time_step2, number_of_rows2)\n",
    "y = medianRRandPlot(rr, filtered_2)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "_ = plt.hist(y[500:4500], bins=40)\n",
    "\n",
    "print('No filtered')\n",
    "rawVariances(data, 500, 4500)\n",
    "print('Filtered')\n",
    "rawVariances(filtered_2, 500, 4500)\n",
    "print(\"Median variance is %s\" \n",
    "      %(statistics.pvariance(y[500:4500])))\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"1_Stave_supine_static.txt\"\n",
    "df=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "df =preProcessDF(df, 100)\n",
    "y, filtered = findRR(df, 100)\n",
    "histoAndVariances(df, filtered, y,500, 4500)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"2_Mattress_supine.txt\"\n",
    "df=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "df =preProcessDF(df, 100)\n",
    "y, filtered = findRR(df, 100)\n",
    "histoAndVariances(df, filtered, y,500, 4500)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"3_Subject_sitting_chair.txt\"\n",
    "df=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "df =preProcessDF(df, 100)\n",
    "y, filtered = findRR(df, 100)\n",
    "histoAndVariances(df, filtered, y,500, 4500)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"4_Chest_sweater.txt\"\n",
    "df=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "df =preProcessDF(df, 100)\n",
    "y, filtered = findRR(df, 100)\n",
    "histoAndVariances(df, filtered, y,500, 4500)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"5_Under_chair.txt\"\n",
    "df=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "df =preProcessDF(df, 100)\n",
    "y, filtered = findRR(df, 100)\n",
    "histoAndVariances(df, filtered, y,500, 4500)\n",
    "\n",
    "# Made by Xabier Galar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "\n",
    "file_name=\"center_sternum.txt\"\n",
    "data=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "time_step1 = 1/200\n",
    "index = data.index\n",
    "number_of_rows1 = len(index)\n",
    "time_vec1 = np.arange(0, number_of_rows1 * time_step1, time_step1)\n",
    "data.insert(0, 'new_seconds', time_vec1)\n",
    "data =data.drop(columns=['Log Mode', 'Log Freq', 'Timestamp'])\n",
    "data\n",
    "\n",
    "# Dropping the begining and the end of the dataset\n",
    "data = data.drop(data.index[0:2000])\n",
    "data = data.drop(data.index[10000:16505])\n",
    "\n",
    "index = data.index\n",
    "number_of_rows1 = len(index)\n",
    "\n",
    "T = 0.005\n",
    "nsamples = 16506\n",
    "t = np.arange(0, number_of_rows1* T, T)\n",
    "\n",
    "x = data['AccX'] \n",
    "y = sp.signal.medfilt(x,21) \n",
    "print(y.shape)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered AccX',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=5.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['AccY'] \n",
    "y = sp.signal.medfilt(x,21) \n",
    "print(y.shape)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered AccY',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['AccZ'] \n",
    "y = sp.signal.medfilt(x,21) \n",
    "print(y.shape)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered AccZ',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['GyroX'] \n",
    "y = sp.signal.medfilt(x,21) \n",
    "print(y.shape)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered GyroX',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['GyroY'] \n",
    "y = sp.signal.medfilt(x,21) \n",
    "print(y.shape)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered GyroY',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['GyroZ'] \n",
    "y = sp.signal.medfilt(x,21) \n",
    "print(y.shape)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered GyroZ',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['MagnX'] \n",
    "y = sp.signal.medfilt(x,21) \n",
    "print(y.shape)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered MagnX',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['MagnY'] \n",
    "y = sp.signal.medfilt(x,21) \n",
    "print(y.shape)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered MagnY',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['MagnZ'] \n",
    "y = sp.signal.medfilt(x,21) \n",
    "print(y.shape)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered MagnZ',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy as sp\n",
    "file_name=\"1_Stave_supine_static.txt\"\n",
    "data=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "data\n",
    "time_step2 = 1/100\n",
    "# Dropping the begining and the end of the dataset\n",
    "\n",
    "\n",
    "data = data.drop(data.index[0:1500])\n",
    "data = data.drop(data.index[4500:9170])\n",
    "\n",
    "\n",
    "\n",
    "index = data.index\n",
    "number_of_rows2 = len(index)\n",
    "t= np.arange(0, number_of_rows2 * time_step2, time_step2)\n",
    "data.insert(0, 'new_seconds', t)\n",
    "data =data.drop(columns=['Log Mode', 'Log Freq', 'Timestamp'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sample_rate=200\n",
    "window_length=21\n",
    "\n",
    "\n",
    "\n",
    "x = data['AccX'] \n",
    "y=sp.signal.savgol_filter(x, window_length, polyorder=1)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered AccX', size=100)\n",
    "plt.xlabel('time', size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=5.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['AccY'] \n",
    "y=sp.signal.savgol_filter(x, window_length, polyorder=1)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered AccY',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['AccZ'] \n",
    "y=sp.signal.savgol_filter(x, window_length, polyorder=1)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered AccZ',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['GyroX'] \n",
    "y=sp.signal.savgol_filter(x, window_length, polyorder=1)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered GyroX',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['GyroY'] \n",
    "y=sp.signal.savgol_filter(x, window_length, polyorder=1)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered GyroY',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['GyroZ'] \n",
    "y=sp.signal.savgol_filter(x, window_length, polyorder=1)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered GyroZ',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['MagnX'] \n",
    "y=sp.signal.savgol_filter(x, window_length, polyorder=1)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered MagnX',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['MagnY'] \n",
    "y=sp.signal.savgol_filter(x, window_length, polyorder=1)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered MagnY',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n",
    "x = data['MagnZ'] \n",
    "y=sp.signal.savgol_filter(x, window_length, polyorder=1)\n",
    "plt.figure(figsize=(100,40))\n",
    "plt.title('Filtered MagnZ',size=100)\n",
    "plt.xlabel('time',size=100)\n",
    "plt.xticks(size = 50)\n",
    "plt.yticks(size = 50)\n",
    "plt.plot(t,x)\n",
    "plt.plot(t,y,c='r',linewidth=7.0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WAVELET TRANSFORM done by Dyutideepta Banerjee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wavelet transform is a tool that has high resolution in the frequency domain and also in the time domain, that allows us to know at which frequencies the signal oscillates, and at which time these oscillations occur.<br>\n",
    "Scaleogram is a special kind of spectogram, but in the case of wavelet the resolution in time vary with the scale value on the Y axis.\n",
    "In a wavelet formalism, a scaleogram is a 2D representation of a 1D data with X axis as time and Y axis as signal periodicity to which the time transform is sensitive to. The value correspond to the amplitude of the signal variation measured which are location at time X and have a periodicity Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References used <br>\n",
    "https://paos.colorado.edu/research/wavelets/ <br>\n",
    "https://pywavelets.readthedocs.io/en/latest/ref/thresholding-functions.html <br>\n",
    "http://profesores.elo.utfsm.cl/~mzanartu/IPD414/Docs/wavelet_ug.pdf <br>\n",
    "https://github.com/mnf2014/article_fft_wavelet_ecg/blob/develop/wavelet_article_octo.ipynb <br>\n",
    "https://dsp.stackexchange.com/questions/15823/feature-extraction-reduction-using-dwt <br>\n",
    "https://www.researchgate.net/post/How_to_run_Wavelet_analysis_in_Python_or_R_or_Matlab <br>\n",
    "https://www.kaggle.com/asauve/a-gentle-introduction-to-wavelet-for-data-analysis <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MANDATORY DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have selected a part of the whole dataframe for Wavelet analysis. <br>\n",
    "Here, I have manually sliced only 1000 points of the dataframe from the 'good' region of the dataframe.\n",
    "I have then attempted to understand the behaviour of the signal using wavelet coefficients and scaleogram. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"center_sternum.txt\"\n",
    "data=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "time_step1 = 1/200\n",
    "index = data.index\n",
    "number_of_rows1 = len(index)\n",
    "time_vec1 = np.arange(0, number_of_rows1 * time_step1, time_step1)\n",
    "data.insert(0, 'new_seconds', time_vec1)\n",
    "data =data.drop(columns=['Log Mode', 'Log Freq', 'Timestamp'])\n",
    "#Slicing\n",
    "data_test = data.iloc[5000:6000,:]\n",
    "t = data_test.iloc[:,0] \n",
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GyroX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat = pywt.thresholding.soft(cA2, np.std(cA2)/2)\n",
    "# cdt = pywt.thresholding.soft(cD2, np.std(cD2)/2)\n",
    "normGX = data_test.loc[:,\"GyroX\"]/max(data_test.loc[:,\"GyroX\"])\n",
    "ts = normGX\n",
    "\n",
    "(ca, cd) = pywt.dwt(ts,'haar') #Finding coefficients of wavelet transform \n",
    "\n",
    "cat = pywt.threshold(ca, np.std(ca)/2, mode='soft')\n",
    "cdt = pywt.threshold(ca, np.std(cd)/2, mode='soft')\n",
    "\n",
    "#ts_rec = pywt.idwt(cat, cdt, 'haar') #reconstructing a new signal using tramsform coefficients\n",
    "denoise = denoise_wavelet(ts, method = 'BayesShrink', mode = 'soft', wavelet_levels = 3, \n",
    "                          wavelet = 'sym8', rescale_sigma = 'True') #reconstructing a new denoised signal\n",
    "#plt.close('all')\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.subplot(211)\n",
    "# Original coefficients\n",
    "plt.plot(ca, '--*b')\n",
    "plt.plot(cd, '--*r')\n",
    "# Thresholded coefficients\n",
    "plt.plot(cat, '--*c')\n",
    "plt.plot(cdt, '--*m')\n",
    "plt.legend(['ca','cd','ca_thresh', 'cd_thresh'], loc = 'best', fontsize=15)\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in ec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Coefficient and Threshold of GyroX')\n",
    "\n",
    "plt.subplot(212)\n",
    "#plt.plot(ts_rec, 'r')\n",
    "plt.plot(ts.to_numpy(), '--*r')\n",
    "plt.plot(denoise, 'b')\n",
    "#plt.hold('on')\n",
    "plt.legend(['original signal', 'reconstructed signal'], loc = 'best', fontsize=15)\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in sec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original and Reconstructed Signals of GyroX')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous wavelet transform\n",
    "\n",
    "scale = np.arange(1,200)\n",
    "coef, freqs = pywt.cwt(normGX, scale,'morl') #Finding coefficiets using Morlet meth=hos\n",
    "#Plotting\n",
    "plt.imshow(abs(coef), interpolation = 'bilinear', cmap='PRGn', aspect = 'auto', \n",
    "           vmax = abs(coef).max(), vmin = abs(coef).min()) # doctest: +SKIP\n",
    "plt.gca().invert_yaxis()\n",
    "# plt.yticks(np.arange(1,len(normGX),1))\n",
    "# plt.xticks(np.arange(0,201,10))\n",
    "plt.show()\n",
    "# #plt.plot(abs(coef))\n",
    "\n",
    "scg.set_default_wavelet('morl')\n",
    "\n",
    "#nn = 33\n",
    "signal_length = 1200\n",
    "# range of scales to perform the transform\n",
    "scales = scg.periods2scales( np.arange(1, signal_length+1) ) #Setting the scale for scaleogram\n",
    "x_values_wvt_arr = normGX\n",
    "\n",
    "# plot the signal \n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(9, 3.5));  \n",
    "ax1.plot(t, x_values_wvt_arr, linewidth=3, color='blue')\n",
    "#ax1.set_xlim(0, 2)\n",
    "ax1.set_title(\"Norm of GyroX signal\")\n",
    "\n",
    "# the scaleogram\n",
    "scg.cws(x_values_wvt_arr, scales=scales, figsize=(10, 4.0), coi = False, ylabel=\"Period\", xlabel=\"Time\",\n",
    "        title='Norm of GyroX signal: scaleogram with linear period'); \n",
    "\n",
    "print(\"Default wavelet function used to compute the transform:\", scg.get_default_wavelet(), \"(\",\n",
    "      pywt.ContinuousWavelet(scg.get_default_wavelet()).family_name, \")\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GyroY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normGY = data_test.loc[:,\"GyroY\"]/max(data_test.loc[:,\"GyroY\"])\n",
    "ts = normGY\n",
    "\n",
    "(ca, cd) = pywt.dwt(ts,'haar') #Finding coefficients of wavelet transform \n",
    "\n",
    "cat = pywt.threshold(ca, np.std(ca)/2, mode='soft')\n",
    "cdt = pywt.threshold(ca, np.std(cd)/2, mode='soft')\n",
    "\n",
    "#ts_rec = pywt.idwt(cat, cdt, 'haar') #reconstructing a new signal using tramsform coefficients\n",
    "denoise = denoise_wavelet(ts, method = 'BayesShrink', mode = 'soft', wavelet_levels = 3, \n",
    "                          wavelet = 'sym8', rescale_sigma = 'True') #reconstructing a new denoised signal\n",
    "#plt.close('all')\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.subplot(211)\n",
    "# Original coefficients\n",
    "plt.plot(ca, '--*b')\n",
    "plt.plot(cd, '--*r')\n",
    "# Thresholded coefficients\n",
    "plt.plot(cat, '--*c')\n",
    "plt.plot(cdt, '--*m')\n",
    "plt.legend(['ca','cd','ca_thresh', 'cd_thresh'], loc = 'best', fontsize=15)\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in ec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Coefficient and Threshold of GyroY')\n",
    "\n",
    "plt.subplot(212)\n",
    "#plt.plot(ts_rec, 'r')\n",
    "plt.plot(ts.to_numpy(), '--*r')\n",
    "plt.plot(denoise, 'b')\n",
    "#plt.hold('on')\n",
    "plt.legend(['original signal', 'reconstructed signal'], loc = 'best', fontsize=15)\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in sec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original and Reconstructed Signals of GyroY')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous wavelet transform\n",
    "\n",
    "scale = np.arange(1,200)\n",
    "coef, freqs = pywt.cwt(normGY, scale,'morl')\n",
    "\n",
    "plt.imshow(abs(coef), interpolation = 'bilinear', cmap='PRGn', aspect = 'auto', \n",
    "           vmax = abs(coef).max(), vmin = abs(coef).min()) # doctest: +SKIP\n",
    "plt.gca().invert_yaxis()\n",
    "# plt.yticks(np.arange(1,len(normGX),1))\n",
    "# plt.xticks(np.arange(0,201,10))\n",
    "plt.show()\n",
    "# #plt.plot(abs(coef))\n",
    "\n",
    "scg.set_default_wavelet('morl')\n",
    "\n",
    "#nn = 33\n",
    "signal_length = 1200\n",
    "# range of scales to perform the transform\n",
    "scales = scg.periods2scales( np.arange(1, signal_length+1) )\n",
    "x_values_wvt_arr = normGY\n",
    "\n",
    "# plot the signal \n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(9, 3.5));  \n",
    "ax1.plot(t, x_values_wvt_arr, linewidth=3, color='blue')\n",
    "#ax1.set_xlim(0, 2)\n",
    "ax1.set_title(\"Norm of GyroY signal\")\n",
    "\n",
    "# the scaleogram\n",
    "scg.cws(x_values_wvt_arr, scales=scales, figsize=(10, 4.0), coi = False, ylabel=\"Period\", xlabel=\"Time\",\n",
    "        title='Norm of GyroY signal: scaleogram with linear period'); \n",
    "\n",
    "print(\"Default wavelet function used to compute the transform:\", scg.get_default_wavelet(), \"(\",\n",
    "      pywt.ContinuousWavelet(scg.get_default_wavelet()).family_name, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GyroZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normGZ = data_test.loc[:,\"GyroZ\"]/max(data_test.loc[:,\"GyroZ\"])\n",
    "ts = normGZ\n",
    "\n",
    "(ca, cd) = pywt.dwt(ts,'haar') #Finding coefficients of wavelet transform \n",
    "\n",
    "cat = pywt.threshold(ca, np.std(ca)/2, mode='soft')\n",
    "cdt = pywt.threshold(ca, np.std(cd)/2, mode='soft')\n",
    "\n",
    "#ts_rec = pywt.idwt(cat, cdt, 'haar') #reconstructing a new signal using tramsform coefficients\n",
    "denoise = denoise_wavelet(ts, method = 'BayesShrink', mode = 'soft', wavelet_levels = 3, \n",
    "                          wavelet = 'sym8', rescale_sigma = 'True') #reconstructing a new denoised signal\n",
    "#plt.close('all')\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.subplot(211)\n",
    "# Original coefficients\n",
    "plt.plot(ca, '--*b')\n",
    "plt.plot(cd, '--*r')\n",
    "# Thresholded coefficients\n",
    "plt.plot(cat, '--*c')\n",
    "plt.plot(cdt, '--*m')\n",
    "plt.legend(['ca','cd','ca_thresh', 'cd_thresh'], loc = 'best', fontsize=15)\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in ec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Coefficient and Threshold of GyroZ')\n",
    "\n",
    "plt.subplot(212)\n",
    "#plt.plot(ts_rec, 'r')\n",
    "plt.plot(ts.to_numpy(), '--*r')\n",
    "plt.plot(denoise, 'b')\n",
    "#plt.hold('on')\n",
    "plt.legend(['original signal', 'reconstructed signal'], loc = 'best', fontsize=15)\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in sec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original and Reconstructed Signals of GyroZ')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous wavelet transform\n",
    "\n",
    "scale = np.arange(1,200)\n",
    "coef, freqs = pywt.cwt(normGZ, scale,'morl')\n",
    "\n",
    "plt.imshow(abs(coef), interpolation = 'bilinear', cmap='PRGn', aspect = 'auto', \n",
    "           vmax = abs(coef).max(), vmin = abs(coef).min()) # doctest: +SKIP\n",
    "plt.gca().invert_yaxis()\n",
    "# plt.yticks(np.arange(1,len(normGX),1))\n",
    "# plt.xticks(np.arange(0,201,10))\n",
    "plt.show()\n",
    "# #plt.plot(abs(coef))\n",
    "\n",
    "scg.set_default_wavelet('morl')\n",
    "\n",
    "#nn = 33\n",
    "signal_length = 1200\n",
    "# range of scales to perform the transform\n",
    "scales = scg.periods2scales( np.arange(1, signal_length+1) )\n",
    "x_values_wvt_arr = normGZ\n",
    "\n",
    "# plot the signal \n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(9, 3.5));  \n",
    "ax1.plot(t, x_values_wvt_arr, linewidth=3, color='blue')\n",
    "#ax1.set_xlim(0, 2)\n",
    "ax1.set_title(\"Norm of GyroZ signal\")\n",
    "\n",
    "# the scaleogram\n",
    "scg.cws(x_values_wvt_arr, scales=scales, figsize=(10, 4.0), coi = False, ylabel=\"Period\", xlabel=\"Time\",\n",
    "        title='Norm of GyroZ signal: scaleogram with linear period'); \n",
    "\n",
    "print(\"Default wavelet function used to compute the transform:\", scg.get_default_wavelet(), \"(\",\n",
    "      pywt.ContinuousWavelet(scg.get_default_wavelet()).family_name, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPTIONAL DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again, I have manually sliced to have 500 data samples for the wavelet analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"1_Stave_supine_static.txt\"#\"C:/Users/Xabier Galar/High Level project/LCP_projects_Y3-Group25/1_Stave_supine_static.txt\"\n",
    "data2=pd.read_csv(file_name, delimiter=\"\\t\")\n",
    "time_step2 = 1/100\n",
    "index = data2.index\n",
    "number_of_rows2 = len(index)\n",
    "time_vec2 = np.arange(0, number_of_rows2 * time_step2, time_step2)\n",
    "data2.insert(0, 'new_seconds', time_vec2)\n",
    "data2 =data2.drop(columns=['Log Mode', 'Log Freq', 'Timestamp'])\n",
    "#Slicing\n",
    "data_test2 = data2.iloc[2000:2500,:]\n",
    "t = data_test2.iloc[:,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GyroX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normGX = data_test2.loc[:,\"GyroX\"]/max(data_test2.loc[:,\"GyroX\"])\n",
    "ts = normGX\n",
    "\n",
    "(ca, cd) = pywt.dwt(ts,'haar') #Finding coefficients of wavelet transform \n",
    "\n",
    "cat = pywt.threshold(ca, np.std(ca)/2, mode='soft')\n",
    "cdt = pywt.threshold(ca, np.std(cd)/2, mode='soft')\n",
    "\n",
    "#ts_rec = pywt.idwt(cat, cdt, 'haar') #reconstructing a new signal using tramsform coefficients\n",
    "denoise = denoise_wavelet(ts, method = 'BayesShrink', mode = 'soft', wavelet_levels = 3, \n",
    "                          wavelet = 'sym8', rescale_sigma = 'True') #reconstructing a new denoised signal\n",
    "#plt.close('all')\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.subplot(211)\n",
    "# Original coefficients\n",
    "plt.plot(ca, '--*b')\n",
    "plt.plot(cd, '--*r')\n",
    "# Thresholded coefficients\n",
    "plt.plot(cat, '--*c')\n",
    "plt.plot(cdt, '--*m')\n",
    "plt.legend(['ca','cd','ca_thresh', 'cd_thresh'], loc = 'best', fontsize=15)\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in ec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Coefficient and Threshold of GyroX')\n",
    "\n",
    "plt.subplot(212)\n",
    "#plt.plot(ts_rec, 'r')\n",
    "plt.plot(ts.to_numpy(), '--*r')\n",
    "plt.plot(denoise, 'b')\n",
    "#plt.hold('on')\n",
    "plt.legend(['original signal', 'reconstructed signal'], loc = 'best', fontsize=15)#, 'reconstructed signal'])\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in sec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original and Reconstructed Signals of GyroX')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous wavelet transform\n",
    "\n",
    "scale = np.arange(1,200)\n",
    "coef, freqs = pywt.cwt(normGX, scale,'morl') #finding coefficients of continuous transform\n",
    "#plotting\n",
    "plt.imshow(abs(coef), interpolation = 'bilinear', cmap='PRGn', aspect = 'auto', \n",
    "           vmax = abs(coef).max(), vmin = abs(coef).min()) # doctest: +SKIP\n",
    "plt.gca().invert_yaxis()\n",
    "# plt.yticks(np.arange(1,len(normGX),1))\n",
    "# plt.xticks(np.arange(0,201,10))\n",
    "plt.show()\n",
    "# #plt.plot(abs(coef))\n",
    "\n",
    "scg.set_default_wavelet('morl')\n",
    "\n",
    "#nn = 33\n",
    "signal_length = 2000\n",
    "# range of scales to perform the transform\n",
    "scales = scg.periods2scales( np.arange(1, signal_length+1) ) #Setting scale of the scaleogram\n",
    "x_values_wvt_arr = normGX\n",
    "\n",
    "# plot the signal \n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(9, 3.5));  \n",
    "ax1.plot(t, x_values_wvt_arr, linewidth=3, color='blue')\n",
    "#ax1.set_xlim(0, 2)\n",
    "ax1.set_title(\"Norm of GyroX signal\")\n",
    "\n",
    "# the scaleogram\n",
    "scg.cws(x_values_wvt_arr, scales=scales, figsize=(10, 4.0), coi = False, ylabel=\"Period\", xlabel=\"Time\",\n",
    "        title='Norm of GyroX signal: scaleogram with linear period'); \n",
    "\n",
    "print(\"Default wavelet function used to compute the transform:\", scg.get_default_wavelet(), \"(\",\n",
    "      pywt.ContinuousWavelet(scg.get_default_wavelet()).family_name, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GyroY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normGY = data_test2.loc[:,\"GyroY\"]/max(data_test2.loc[:,\"GyroY\"])\n",
    "ts = normGY\n",
    "\n",
    "(ca, cd) = pywt.dwt(ts,'haar') #Finding coefficients of wavelet transform \n",
    "\n",
    "cat = pywt.threshold(ca, np.std(ca)/2, mode='soft')\n",
    "cdt = pywt.threshold(ca, np.std(cd)/2, mode='soft')\n",
    "\n",
    "#ts_rec = pywt.idwt(cat, cdt, 'haar') #reconstructing a new signal using tramsform coefficients\n",
    "denoise = denoise_wavelet(ts, method = 'BayesShrink', mode = 'soft', wavelet_levels = 3, \n",
    "                          wavelet = 'sym8', rescale_sigma = 'True') #reconstructing a new denoised signal\n",
    "#plt.close('all')\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.subplot(211)\n",
    "# Original coefficients\n",
    "plt.plot(ca, '--*b')\n",
    "plt.plot(cd, '--*r')\n",
    "# Thresholded coefficients\n",
    "plt.plot(cat, '--*c')\n",
    "plt.plot(cdt, '--*m')\n",
    "plt.legend(['ca','cd','ca_thresh', 'cd_thresh'], loc = 'best', fontsize=15)\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in ec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Coefficient and Threshold of GyroY')\n",
    "\n",
    "plt.subplot(212)\n",
    "#plt.plot(ts_rec, 'r')\n",
    "plt.plot(ts.to_numpy(), '--*r')\n",
    "plt.plot(denoise, 'b')\n",
    "#plt.hold('on')\n",
    "plt.legend(['original signal', 'reconstructed signal'], loc = 'best', fontsize=15)#, 'reconstructed signal'])\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in sec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original and Reconstructed Signals of GyroY')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous wavelet transform\n",
    "\n",
    "scale = np.arange(1,200)\n",
    "coef, freqs = pywt.cwt(normGY, scale,'morl')\n",
    "\n",
    "plt.imshow(abs(coef), interpolation = 'bilinear', cmap='PRGn', aspect = 'auto', \n",
    "           vmax = abs(coef).max(), vmin = abs(coef).min()) # doctest: +SKIP\n",
    "plt.gca().invert_yaxis()\n",
    "# plt.yticks(np.arange(1,len(normGX),1))\n",
    "# plt.xticks(np.arange(0,201,10))\n",
    "plt.show()\n",
    "# plt.plot(t,normGX)\n",
    "# #plt.plot(abs(coef))\n",
    "\n",
    "scg.set_default_wavelet('morl')\n",
    "\n",
    "#nn = 33\n",
    "signal_length = 2000\n",
    "# range of scales to perform the transform\n",
    "scales = scg.periods2scales( np.arange(1, signal_length+1) )\n",
    "x_values_wvt_arr = normGY\n",
    "\n",
    "# plot the signal \n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(9, 3.5));  \n",
    "ax1.plot(t, x_values_wvt_arr, linewidth=3, color='blue')\n",
    "#ax1.set_xlim(0, 2)\n",
    "ax1.set_title(\"Norm of GyroY signal\")\n",
    "\n",
    "# the scaleogram\n",
    "scg.cws(x_values_wvt_arr, scales=scales, figsize=(10, 4.0), coi = False, ylabel=\"Period\", xlabel=\"Time\",\n",
    "        title='Norm of GyroY signal: scaleogram with linear period'); \n",
    "\n",
    "print(\"Default wavelet function used to compute the transform:\", scg.get_default_wavelet(), \"(\",\n",
    "      pywt.ContinuousWavelet(scg.get_default_wavelet()).family_name, \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GyroZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normGZ = data_test2.loc[:,\"GyroZ\"]/max(data_test2.loc[:,\"GyroZ\"])\n",
    "ts = normGZ\n",
    "\n",
    "(ca, cd) = pywt.dwt(ts,'haar') #Finding coefficients of wavelet transform \n",
    "\n",
    "cat = pywt.threshold(ca, np.std(ca)/2, mode='soft')\n",
    "cdt = pywt.threshold(ca, np.std(cd)/2, mode='soft')\n",
    "\n",
    "#ts_rec = pywt.idwt(cat, cdt, 'haar') #reconstructing a new signal using tramsform coefficients\n",
    "denoise = denoise_wavelet(ts, method = 'BayesShrink', mode = 'soft', wavelet_levels = 3, \n",
    "                          wavelet = 'sym8', rescale_sigma = 'True') #reconstructing a new denoised signal\n",
    "#plt.close('all')\n",
    "plt.figure(figsize=(30, 20))\n",
    "plt.subplot(211)\n",
    "# Original coefficients\n",
    "plt.plot(ca, '--*b')\n",
    "plt.plot(cd, '--*r')\n",
    "# Thresholded coefficients\n",
    "plt.plot(cat, '--*c')\n",
    "plt.plot(cdt, '--*m')\n",
    "plt.legend(['ca','cd','ca_thresh', 'cd_thresh'], loc = 'best', fontsize=15)\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in ec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Coefficient and Threshold of GyroZ')\n",
    "\n",
    "plt.subplot(212)\n",
    "#plt.plot(ts_rec, 'r')\n",
    "plt.plot(ts.to_numpy(), '--*r')\n",
    "plt.plot(denoise, 'b')\n",
    "#plt.hold('on')\n",
    "plt.legend(['original signal', 'reconstructed signal'], loc = 'best', fontsize=15)#, 'reconstructed signal'])\n",
    "plt.grid('on')\n",
    "plt.xlabel('time in sec')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Original and Reconstructed Signals of GyroZ')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Continuous wavelet transform\n",
    "\n",
    "scale = np.arange(1,200)\n",
    "coef, freqs = pywt.cwt(normGZ, scale,'morl')\n",
    "\n",
    "plt.imshow(abs(coef), interpolation = 'bilinear', cmap='PRGn', aspect = 'auto', \n",
    "           vmax = abs(coef).max(), vmin = abs(coef).min()) # doctest: +SKIP\n",
    "plt.gca().invert_yaxis()\n",
    "# plt.yticks(np.arange(1,len(normGX),1))\n",
    "# plt.xticks(np.arange(0,201,10))\n",
    "plt.show()\n",
    "# plt.plot(t,normGX)\n",
    "# #plt.plot(abs(coef))\n",
    "\n",
    "scg.set_default_wavelet('morl')\n",
    "\n",
    "#nn = 33\n",
    "signal_length = 2000\n",
    "# range of scales to perform the transform\n",
    "scales = scg.periods2scales( np.arange(1, signal_length+1) )\n",
    "x_values_wvt_arr = normGZ\n",
    "\n",
    "# plot the signal \n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(9, 3.5));  \n",
    "ax1.plot(t, x_values_wvt_arr, linewidth=3, color='blue')\n",
    "#ax1.set_xlim(0, 2)\n",
    "ax1.set_title(\"Norm of GyroZ signal\")\n",
    "\n",
    "# the scaleogram\n",
    "scg.cws(x_values_wvt_arr, scales=scales, figsize=(10, 4.0), coi = False, ylabel=\"Period\", xlabel=\"Time\",\n",
    "        title='Norm of GyroZ signal: scaleogram with linear period'); \n",
    "\n",
    "print(\"Default wavelet function used to compute the transform:\", scg.get_default_wavelet(), \"(\",\n",
    "      pywt.ContinuousWavelet(scg.get_default_wavelet()).family_name, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
